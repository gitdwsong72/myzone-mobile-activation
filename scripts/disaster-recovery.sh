#!/bin/bash

# ì¬í•´ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
# ë°±ì—…ì—ì„œ ì‹œìŠ¤í…œì„ ë³µêµ¬í•©ë‹ˆë‹¤.

set -e

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# í•¨ìˆ˜ ì •ì˜
log_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

log_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

log_error() {
    echo -e "${RED}âŒ $1${NC}"
}

# ì‚¬ìš©ë²• ì¶œë ¥
usage() {
    echo "ì‚¬ìš©ë²•: $0 [ì˜µì…˜]"
    echo ""
    echo "ì˜µì…˜:"
    echo "  --backup-file FILE    ë³µêµ¬í•  ë°±ì—… íŒŒì¼ ì§€ì •"
    echo "  --backup-date DATE    ë³µêµ¬í•  ë°±ì—… ë‚ ì§œ ì§€ì • (YYYY-MM-DD)"
    echo "  --list-backups        ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—… ëª©ë¡ í‘œì‹œ"
    echo "  --dry-run            ì‹¤ì œ ë³µêµ¬ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ë§Œ ì‹¤í–‰"
    echo "  --force              í™•ì¸ ì—†ì´ ê°•ì œ ë³µêµ¬"
    echo ""
    echo "ì˜ˆì‹œ:"
    echo "  $0 --backup-date 2024-01-15"
    echo "  $0 --backup-file /backups/myzone_backup_20240115_030000.sql.gz"
    echo "  $0 --list-backups"
    echo ""
    exit 1
}

# ë°±ì—… ëª©ë¡ í‘œì‹œ
list_backups() {
    log_info "ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—… íŒŒì¼:"
    echo ""
    
    # ë¡œì»¬ ë°±ì—…
    if [[ -d "backups" ]]; then
        echo "ë¡œì»¬ ë°±ì—…:"
        ls -la backups/myzone_backup_*.sql.gz 2>/dev/null | while read -r line; do
            echo "  $line"
        done
        echo ""
    fi
    
    # S3 ë°±ì—… (AWS CLIê°€ ì„¤ì¹˜ëœ ê²½ìš°)
    if command -v aws &> /dev/null && [[ ! -z "${BACKUP_S3_BUCKET}" ]]; then
        echo "S3 ë°±ì—…:"
        aws s3 ls s3://${BACKUP_S3_BUCKET}/database-backups/ | while read -r line; do
            echo "  $line"
        done
    fi
}

# ë°±ì—… íŒŒì¼ ë‹¤ìš´ë¡œë“œ (S3ì—ì„œ)
download_backup() {
    local backup_file="$1"
    local local_file="backups/$(basename $backup_file)"
    
    if command -v aws &> /dev/null && [[ ! -z "${BACKUP_S3_BUCKET}" ]]; then
        log_info "S3ì—ì„œ ë°±ì—… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘..."
        aws s3 cp "s3://${BACKUP_S3_BUCKET}/database-backups/$backup_file" "$local_file"
        echo "$local_file"
    else
        log_error "AWS CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ S3 ë²„í‚·ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        exit 1
    fi
}

# ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
restore_database() {
    local backup_file="$1"
    
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì‹œì‘..."
    log_info "ë°±ì—… íŒŒì¼: $backup_file"
    
    # ë°±ì—… íŒŒì¼ ì¡´ì¬ í™•ì¸
    if [[ ! -f "$backup_file" ]]; then
        log_error "ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $backup_file"
        exit 1
    fi
    
    # í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (ì•ˆì „ì¥ì¹˜)
    log_info "í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì¤‘..."
    CURRENT_BACKUP="backups/pre-restore-$(date +%Y%m%d_%H%M%S).sql"
    docker-compose -f docker-compose.prod.yml exec -T db pg_dump -U "$POSTGRES_USER" -d "$POSTGRES_DB" > "$CURRENT_BACKUP"
    log_success "í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ: $CURRENT_BACKUP"
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ì§€
    log_info "ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ì§€ ì¤‘..."
    docker-compose -f docker-compose.prod.yml stop backend frontend
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ ì¤‘..."
    docker-compose -f docker-compose.prod.yml exec -T db psql -U "$POSTGRES_USER" -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = '$POSTGRES_DB' AND pid <> pg_backend_pid();"
    
    # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ë° ì¬ìƒì„±
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ì¬ìƒì„± ì¤‘..."
    docker-compose -f docker-compose.prod.yml exec -T db psql -U "$POSTGRES_USER" -d postgres -c "DROP DATABASE IF EXISTS $POSTGRES_DB;"
    docker-compose -f docker-compose.prod.yml exec -T db psql -U "$POSTGRES_USER" -d postgres -c "CREATE DATABASE $POSTGRES_DB;"
    
    # ë°±ì—… ë³µì›
    log_info "ë°±ì—… ë³µì› ì¤‘..."
    if [[ "$backup_file" == *.gz ]]; then
        gunzip -c "$backup_file" | docker-compose -f docker-compose.prod.yml exec -T db psql -U "$POSTGRES_USER" -d "$POSTGRES_DB"
    else
        docker-compose -f docker-compose.prod.yml exec -T db psql -U "$POSTGRES_USER" -d "$POSTGRES_DB" < "$backup_file"
    fi
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘..."
    docker-compose -f docker-compose.prod.yml exec -T backend alembic upgrade head
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
    log_info "ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘ ì¤‘..."
    docker-compose -f docker-compose.prod.yml start backend frontend
    
    # í—¬ìŠ¤ì²´í¬
    log_info "í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰ ì¤‘..."
    sleep 30
    
    BACKEND_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/api/v1/health || echo "000")
    FRONTEND_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost/health || echo "000")
    
    if [[ "$BACKEND_HEALTH" == "200" && "$FRONTEND_HEALTH" == "200" ]]; then
        log_success "ë³µêµ¬ ì™„ë£Œ ë° í—¬ìŠ¤ì²´í¬ í†µê³¼"
    else
        log_error "ë³µêµ¬ í›„ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ (Backend: $BACKEND_HEALTH, Frontend: $FRONTEND_HEALTH)"
        log_warning "ì´ì „ ë°±ì—…ìœ¼ë¡œ ë¡¤ë°±ì„ ê³ ë ¤í•˜ì„¸ìš”: $CURRENT_BACKUP"
        exit 1
    fi
}

# íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬
restore_files() {
    local backup_date="$1"
    
    log_info "íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬ ì‹œì‘..."
    
    # ì—…ë¡œë“œ íŒŒì¼ ë°±ì—…
    if [[ -d "backend_uploads_prod" ]]; then
        log_info "í˜„ì¬ ì—…ë¡œë“œ íŒŒì¼ ë°±ì—… ì¤‘..."
        tar -czf "backups/uploads-backup-$(date +%Y%m%d_%H%M%S).tar.gz" backend_uploads_prod/
    fi
    
    # S3ì—ì„œ íŒŒì¼ ë³µêµ¬ (ì„¤ì •ëœ ê²½ìš°)
    if command -v aws &> /dev/null && [[ ! -z "${BACKUP_S3_BUCKET}" ]]; then
        log_info "S3ì—ì„œ íŒŒì¼ ë³µêµ¬ ì¤‘..."
        aws s3 sync "s3://${BACKUP_S3_BUCKET}/file-backups/$backup_date/" backend_uploads_prod/
        log_success "íŒŒì¼ ë³µêµ¬ ì™„ë£Œ"
    else
        log_warning "S3 ì„¤ì •ì´ ì—†ì–´ íŒŒì¼ ë³µêµ¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
    fi
}

# ì„¤ì • íŒŒì¼ ë³µêµ¬
restore_configs() {
    log_info "ì„¤ì • íŒŒì¼ ë³µêµ¬ ì‹œì‘..."
    
    # í˜„ì¬ ì„¤ì • ë°±ì—…
    tar -czf "backups/config-backup-$(date +%Y%m%d_%H%M%S).tar.gz" \
        .env.production \
        secrets/ \
        nginx/ \
        2>/dev/null || true
    
    # Gitì—ì„œ ìµœì‹  ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    log_info "Gitì—ì„œ ìµœì‹  ì„¤ì • ê°€ì ¸ì˜¤ê¸°..."
    git stash
    git pull origin main
    
    log_success "ì„¤ì • íŒŒì¼ ë³µêµ¬ ì™„ë£Œ"
}

# ë©”ì¸ ë¡œì§
main() {
    local BACKUP_FILE=""
    local BACKUP_DATE=""
    local LIST_BACKUPS=false
    local DRY_RUN=false
    local FORCE=false
    
    # íŒŒë¼ë¯¸í„° íŒŒì‹±
    while [[ $# -gt 0 ]]; do
        case $1 in
            --backup-file)
                BACKUP_FILE="$2"
                shift 2
                ;;
            --backup-date)
                BACKUP_DATE="$2"
                shift 2
                ;;
            --list-backups)
                LIST_BACKUPS=true
                shift
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --force)
                FORCE=true
                shift
                ;;
            -h|--help)
                usage
                ;;
            *)
                log_error "ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: $1"
                usage
                ;;
        esac
    done
    
    # ë°±ì—… ëª©ë¡ í‘œì‹œ
    if [[ "$LIST_BACKUPS" == "true" ]]; then
        list_backups
        exit 0
    fi
    
    # ë°±ì—… íŒŒì¼ ë˜ëŠ” ë‚ ì§œ í™•ì¸
    if [[ -z "$BACKUP_FILE" && -z "$BACKUP_DATE" ]]; then
        log_error "ë°±ì—… íŒŒì¼ ë˜ëŠ” ë‚ ì§œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”."
        usage
    fi
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    if [[ -f ".env.production" ]]; then
        set -a
        source .env.production
        if [[ -f "secrets/.env.secrets" ]]; then
            source secrets/.env.secrets
        fi
        set +a
    fi
    
    # ë°±ì—… ë‚ ì§œë¡œ íŒŒì¼ ì°¾ê¸°
    if [[ -n "$BACKUP_DATE" && -z "$BACKUP_FILE" ]]; then
        BACKUP_DATE_FORMATTED=$(echo "$BACKUP_DATE" | tr -d '-')
        BACKUP_FILE=$(find backups/ -name "myzone_backup_${BACKUP_DATE_FORMATTED}_*.sql.gz" | head -1)
        
        if [[ -z "$BACKUP_FILE" ]]; then
            log_warning "ë¡œì»¬ì—ì„œ ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. S3ì—ì„œ ê²€ìƒ‰ ì¤‘..."
            BACKUP_FILE=$(download_backup "myzone_backup_${BACKUP_DATE_FORMATTED}_030000.sql.gz")
        fi
    fi
    
    log_info "MyZone ì¬í•´ ë³µêµ¬ ì‹œì‘"
    log_info "ë°±ì—… íŒŒì¼: $BACKUP_FILE"
    
    # Dry run
    if [[ "$DRY_RUN" == "true" ]]; then
        log_info "DRY RUN ëª¨ë“œ - ì‹¤ì œ ë³µêµ¬ëŠ” ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        log_info "ë³µêµ¬í•  ë°±ì—… íŒŒì¼: $BACKUP_FILE"
        log_info "ë³µêµ¬ ë‹¨ê³„:"
        echo "  1. í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"
        echo "  2. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ì§€"
        echo "  3. ë°ì´í„°ë² ì´ìŠ¤ ë³µì›"
        echo "  4. íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬"
        echo "  5. ì„¤ì • íŒŒì¼ ë³µêµ¬"
        echo "  6. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘"
        echo "  7. í—¬ìŠ¤ì²´í¬"
        exit 0
    fi
    
    # ë³µêµ¬ í™•ì¸
    if [[ "$FORCE" != "true" ]]; then
        log_warning "ì •ë§ë¡œ ì‹œìŠ¤í…œì„ ë³µêµ¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? í˜„ì¬ ë°ì´í„°ê°€ ì†ì‹¤ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (y/n)"
        read -r -p "" response
        if [[ ! "$response" =~ ^[Yy]$ ]]; then
            log_info "ë³µêµ¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
            exit 0
        fi
    fi
    
    # ë³µêµ¬ ì‹¤í–‰
    restore_database "$BACKUP_FILE"
    
    if [[ -n "$BACKUP_DATE" ]]; then
        restore_files "$BACKUP_DATE"
    fi
    
    restore_configs
    
    log_success "ì¬í•´ ë³µêµ¬ ì™„ë£Œ!"
    
    # ìŠ¬ë™ ì•Œë¦¼
    if [[ ! -z "${SLACK_WEBHOOK_URL}" ]]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ğŸ”„ MyZone ì¬í•´ ë³µêµ¬ ì™„ë£Œ\\nğŸ“ ë°±ì—… íŒŒì¼: $(basename $BACKUP_FILE)\\nğŸ“… ì‹œê°„: $(date)\"}" \
            "${SLACK_WEBHOOK_URL}" || true
    fi
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"